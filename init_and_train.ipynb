{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 05:18:10.384133: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-08 05:18:10.451970: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 05:18:11.363185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/zuherj/miniconda3/envs/kws/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import os\n",
    "\n",
    "from dataset import get_datasets\n",
    "from stormer import Stormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105835\n"
     ]
    }
   ],
   "source": [
    "# count all the files inside \"data/speech_commands_v0.02\" directory\n",
    "cnt = 0\n",
    "for root, dirs, files in os.walk(\"data/speech-commands-v2\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".wav\"):\n",
    "            cnt += 1\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example to how to initailize the parameters in case you don't have no model\n",
    "\n",
    "version = 2\n",
    "num_classes = 37 if version == 2 else 31 #### should change\n",
    "dataset_type = \"mel\"\n",
    "frame_length = 256\n",
    "frame_step = 128\n",
    "mel_bands=40\n",
    "num_coefficients=13\n",
    "max_shift_in_ms=100\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 10000  # For real training, use num_epochs=100. 10 is a test value\n",
    "\n",
    "num_heads = 4\n",
    "num_repeats = 2\n",
    "num_state_cells = [10, 10]\n",
    "input_seq_size = 31\n",
    "projection_dim = 32\n",
    "inner_ff_dim = 2 * projection_dim\n",
    "dropout = 0.1\n",
    "probability_of_noise = 0.8\n",
    "\n",
    "hps = {\n",
    "    \"version\": version,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"dataset_type\": dataset_type,\n",
    "    \"frame_length\": frame_length,\n",
    "    \"frame_step\": frame_step,\n",
    "    \"mel_bands\": mel_bands,\n",
    "    \"num_coefficients\": num_coefficients,\n",
    "    \"max_shift_in_ms\": max_shift_in_ms,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_epochs\": num_epochs,\n",
    "    \"num_heads\": num_heads,\n",
    "    \"num_repeats\": num_repeats,\n",
    "    \"num_state_cells\": num_state_cells,\n",
    "    \"input_seq_size\": input_seq_size,\n",
    "    \"projection_dim\": projection_dim,\n",
    "    \"inner_ff_dim\": inner_ff_dim,\n",
    "    \"dropout\": dropout,\n",
    "    \"probability_of_noise\": probability_of_noise,\n",
    "}\n",
    "model_name = utils.get_model_name(**hps)\n",
    "\n",
    "utils.save_hps(model_name, hps)\n",
    "model_path = utils.get_model_path(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 05:18:15.218342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43626 MB memory:  -> device: 0, name: NVIDIA L40S, pci bus id: 0000:27:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "stormer = Stormer(\n",
    "    **hps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset version 2\n",
      "Dataset loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 05:18:18.814327: I tensorflow_io/core/kernels/cpu_check.cc:128] Your CPU supports instructions that this TensorFlow IO binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-05-08 05:18:18.820452: W tensorflow_io/core/kernels/audio_video_mp3_kernels.cc:271] libmp3lame.so.0 or lame functions are not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "## load the datasets\n",
    "train, valid, test = get_datasets(\n",
    "    **hps\n",
    ")\n",
    "\n",
    "# get train size using cardinality\n",
    "train_size = train.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1489"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    }
   ],
   "source": [
    "results_filename = f'data/results/results_r{num_repeats}_h{num_heads}_dm{projection_dim}_dataset={dataset_type}.csv'\n",
    "\n",
    "metrics=[\"accuracy\"]\n",
    "\n",
    "stormer.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "state_transformer_history = stormer.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        utils.MetricsLogger(\n",
    "            results_filename,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
